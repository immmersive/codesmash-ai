# Computable Functions as Compressed Descriptions of Patterns

If our goal is to solve problems, that is transform patterns from initial to desired state, we could go about it in this way.

The reason why we want to know how patterns can be transformed is because we can then allocate resources in the right direction. And being more precise and knowing what we should do, allows us to get to the core of the problem. We then need to use less resources to solve a problem. This is particulary important since our resources are limited and we're working under constraints. During a problem-solving process, we are working with constraints on our resources. Meaning, we only have a limited number of transformations we can apply in order to solve teh problem. Accordign to the Main Axiom, we need to use the right tools for our job when we choose the transformations which we think will get us to the correct solution.

When it comes to transformation of patterns, we want to minimize the path between initial ideas and the final solution. The path, that is, the transformations which are performed in order to convert the idea into the solution, need to be done as efficiently as possible in order to minimize the use of resources. By the theorem of conversion of information into matter, more efficient execution of algorithms, will result in more matter, meaning resources.

In the real world, we are constantly operating under certain constraints. The most obvious constraints we can focus on are natural laws. Here we have certain indicators which we can use to predict the future. By predicting the future we gain information about events and can act accordingly to better reach our goal. This means that the better descriptions we have of natural laws, the better predictions we can make. Simple equations which usually represent natural laws are good representations of reality. 

These descriptions have low Kolmogorov complexity and are thus highly compressible and easily computable, which means that we don't need many steps to get to the result. 

# Example

One example is an empirical experiment which would take a lot more resources than a simple computation and they both give us the same result. The digital domain and the empirical experiment give us the same result. They are basically the same comparison, but the digital one is more succinct. It removes the repetitions from the physical domain and all the operations which are not needed and only focuses on the important ones. Also, we are limiting possible events thus increasing probability of possible events and by that we are increasing information which is needed to make precise predictions. This tells us that we should be moving as many of empirical experiments into the virtual world, because of its benefits. The move needs to be from the physical to the virtual domain. From this, it follows that we need a computational system, which would allow us to run as many calculations as possible, on order to move s much work into the digital domain.

# Generalization of descriptions

When we have certain values which represent real events, it would be good to derive a function which describes them will. This basically means that we have found a general rule which will tell us what will happen under certain circumstances. In other words we have compressed these events using this function which we use as a description. Thus, we now have a pattern which specifies an event and makes it distinct from others. In order to better compress events we should give as much data as possible so that we have a good context, in other words, more information, to compress the events.

In this way, the more context we provide, the better we can compress the function, the more information we provided. Then, the function will be easier to describe relative to the context which gives us more information in a shorter description. The easier the function is to describe the easier it is to manipulate and its algorithmic complexity smaller so we can more easily use it which is ultimately more useful.

Automation is about finding computable functions which can be executed in the physical world. Optimal automation is about finding computable functions which have low Kolmogorov complexity. What we need to do is to move computation, that is, the execution of algorithms, which we can't automate yet, as much as possible into the mental domain. On the other hand, we should move as much of computation which we can automate into the physical domain. We should try to find algorithms which can be implemented in the physical world, which can produce such results that they solve a known problem. This relieves us of doing work which we already know how to perform and lays us work on something we don't know how to do.

This is also needed from an efficiency viewpoint. Namely, machines are good at performing repetitive operations correctly and really fast. But they are not good at finding new solutions to problems. On the other had, the human brain is not good at repetitive tasks but excels at finding new solutions. In other words, human brain should be used when we don't have a computable function for a problem at hand. This is an efficient distribution of resources and is an efficient data structure.

Also, creating computable functions which represents complex events is about finding patterns and by these compressing the description of teh observed events, such that the information about those events is preserved. Thus, by having a computable function, which is shorter than the event it describes, we have shortened the description, i.e. the amount of information which needs to be manipulated, yet preserved the information of the events. This is useful because in order to correctly predict something using this function, we now need less resources to compute the result using the function.

The way we have added information by finding the specific pattern is by removing repetition. In other words we have encoded the repetitive parts of the description such that once the encoded description is manipulated it will produce the same result same as the non-compressed solution.

Thus, our goal is to describe everything using simple computable functions, so that we can predict everything around us, and that we can do it efficiently. The first goes well with the idea that we need predictions in order in order to gain information based on which we will act and to use less resources and the second goes well with the idea that we need less resources because we always need more in the future.

# Data Structures as Compressed Description of States

States in this context ate obviously just patterns. Data structures are patterns to which algorithms are applied, in order to produce certain results. In other words, functions are applied to input patterns and as a result we have output patterns. In the physical world, there are certain patterns, mostly with low KC, which will efficiently give us the result we want, that we would not be able to get had we not had this structure, i.e. the pattern. Thus, we can say that we are abstracting away the unneccessary patterns from the original material resource in order for the process, i.e. the algorithm to efficiently give us the result. In other words, a data structure is an efficient pattern which allows an efficient execution of an algorithm.

It can thus be said that its an abstraction over all possible operations which could be executed on certain physical entities. We simply form it in such a way that once an algorithm is executed, it will gives us the most efficient way of getting us to the result we wanted from the original physical entities.

# Algorithms as Compressed Description of State Changes

Algorithms are compressed descriptions of events, that is pattern transformations, which preserve the original information and are thus easily computable and will give you the same information as the intial larger description, which is more efficient. Data Structures are compressed patterns which can be decompressed using algorithms. The unpacking gives us wanted information. The transformation, that is, the unpacking of the data structure is the execution of the algorithm. Data structures are then simply compressed information, while algorithms are the information which tell us how to unpack the data structure and get the compressed information. The reason why we package it in the first place is to make it easier to manipulate because there is less information to deal with and because this also makes the transformation more efficient.

But that main point that needs to be addressed here, is the issue of efficiency. The way to get the efficiency, is to get the correct data structure, and to get that, means to get the correct abstraction level, with respect to our goal.
